---
showDate: true
summary: "My take on where AI is taking us"
title: "AI and our future"
date: 2025-07-23
draft: true
comments: true
---

## Article summary as a graph
{{< mermaid >}}
graph TD
    A[AI Revolution<br/>Automating thinking itself] --> B[Self-Reinforcing Research<br/>AI improves AI research]
    A --> C[Industrial Revolution Parallel<br/>Manual → Intellectual automation]
    
    B --> D[Research Acceleration<br/>Exponential improvements]
    D --> B
    
    C --> E[Premium Human Content<br/>Like artisanal goods]
    C --> F[Job Displacement<br/>White-collar threat]
    
    F --> G[Mass Unemployment Risk<br/>Fewer new jobs created]
    G --> H[UBI Necessity<br/>Economic requirement]
    
    A --> I[AI Elite Formation<br/>Wealth concentration]
    I --> J[Social Collapse Risk<br/>Inequality crisis]
    
    H --> J
    
    J --> K[Future Choice Point<br/>Human creation we can influence]
    K --> L[Collective Action<br/>Regulation & distribution]
    K --> M[Individual Adaptation<br/>Uniquely human skills]
    
    E --> N[Market Bifurcation<br/>Premium vs mass market]
    N --> E
{{< /mermaid >}}

## Introduction

Unless you have been living in a cave lately, you certainly  heard about AI (artificial intelligence), which in my opinion is going to change the way we live. While every generation believes it's witnessing history's most important transformation, the AI revolution appears different—not just in scope, but in what it targets. Indeed, we are in the process of creating a species smarter than ourselves and, in doing so, we are losing our place as the smartest species on Earth, which was the main reason we managed to dominate our environment. This article examines where we are in this transformation, what history teaches us about technological disruption, and what might come next as we navigate uncharted territory where we are creating a species smarter than ourselves.

## Where are we now?

In the last few years, the general public has witnessed a rapid expansion of AI. I think there are two reasons for that: we are building on top of solid foundations, and second, AI development feeds itself.

First, even though AI got the headlines with ChatGPT recently, it relies on several other successful research projects. For example, the internet has made it possible to access and process knowledge at a scale never imagined before, computer hardware gave rise to highly efficient GPUs which are the core of neural networks such as ChatGPT, and the improvement of Python—an easy‑to‑use language—makes it possible for novice developers to experiment with LLMs.

Secondly, progress in research (and in the case that interests us, ML research on LLMs) is a self‑reinforcing process. The reason for that is one of the often misunderstood properties of research: 90 % of it will be a dead end, but the remaining 10 % will have a huge impact. A good LLM can act as a powerful research assistant that will help identify those 10 %, which should increase the quantity and quality of good research output. And this is the start of a self‑reinforcing process where you create better LLMs that help you do better research that helps you do better LLMs that help you do better research... This results in rapid improvements of AI capabilities which seem to have a much harder time plateauing than other research fields.

In this rapid advancement, as humans, we are seeing our way of working changing significantly as we get to outsource most of our jobs to chatbots and start to witness an internet where a lot of the content is auto‑generated.

## A parallel to be drawn with the Industrial Revolution

To think about the future, let's reflect on the past—specifically, on the rise of manual labor automation and compare it to the intellectual labor automation we are witnessing now.

The Industrial Revolution gives us a blueprint for what might happen. When machines started replacing human muscle power, there was initially a lot of fear and resistance. People were worried about losing their livelihoods, and rightfully so—many traditional crafts and manual jobs simply disappeared.

What we saw was that human‑generated things became premium products. Think about handmade furniture versus mass‑produced IKEA stuff, or artisanal bread versus factory‑made loaves. People started paying more for the "human touch" once machines could do the basic work cheaply and efficiently. There's something about knowing a human crafted something with their hands that adds value.

Only the strongest survived in each industry. The blacksmiths who adapted became specialized metalworkers, the weavers who survived became designers, and new jobs emerged that nobody could have predicted—like machine operators, engineers, and eventually software developers. The key was adaptation and finding where human skills were still irreplaceable.

What's fascinating is how closely the emergence of AI mirrors the Industrial Revolution pattern. Just as steam engines and machinery amplified human muscle power beyond what anyone thought possible, AI is now amplifying human cognitive power in the same way. The steam engine didn't just replace a few workers—it fundamentally changed what it meant to do physical work. Similarly, AI isn't just replacing a few thinkers—it’s changing what it means to do intellectual work. We're seeing the same cycle: initial fear, massive disruption, then adaptation to a new equilibrium where humans and machines work together in ways we couldn't have imagined before.

## Where do we go from here?

In the short term, it is likely we're about to see the same demand‑and‑supply imbalance that hit manual laborers during the Industrial Revolution, except this time it's coming for white‑collar jobs. The need for accountants, lawyers, and software developers will decrease sharply as AI multiplies by two to three the amount of work a single person can perform while demand stays roughly the same. Software engineers, accountants, and lawyers—the knowledge workers who thought they were safe—are going to face the same brutal economics that factory workers faced 150 years ago.

But here's where it gets really ugly from an inequality perspective: we're already seeing a massive bifurcation in who benefits from this transition. AI researchers are getting paid tens of millions of dollars because they're the ones creating the tools, while everyone else is about to see their skills commoditized. It's like being the person who invented the steam engine versus being the person whose job got replaced by the steam engine. The gap between the "AI elite" and everyone else is going to become larger.

Meanwhile, human‑generated content is rapidly becoming the premium option while AI‑generated content becomes the IKEA of the information world—cheap, functional, but lacking that special something. You can already see this happening: people are starting to specifically seek out "human‑written" articles or "human‑coded" software, and they're willing to pay more for it. But just like with handmade furniture, the market for premium human work will be much smaller than the mass market that AI will dominate.

Looking further ahead, the historical parallel gets really interesting. During the Industrial Revolution, when manual jobs disappeared, they were largely replaced by more knowledge‑intensive jobs. Factory workers became engineers, farmers became office workers, and so on. But now we're automating knowledge work itself. So what comes next?

We'll definitely see new jobs emerge around AI—prompt engineers, AI trainers, AI auditors, and roles we can't even imagine yet. But here's the key question: will these new jobs be as numerous as the ones being displaced? History suggests they might not be. When you can replace ten accountants with one AI system that needs only occasional human oversight, the math doesn't work out in favor of employment.

This brings us to a possibility that we've never faced before: we might actually be heading toward a world with fundamentally fewer jobs. During every previous technological revolution, new types of work emerged to absorb displaced workers. But when you're automating thinking itself—the thing that created all those previous "new" jobs—where do you go from there?

This might be when universal basic income stops being a progressive policy idea and becomes an economic necessity. Not because politicians want to be nice, but because the alternative is mass unemployment and social collapse. The challenge will be figuring out how to fund it when most of the value creation is happening through AI systems rather than human labor.

## Conclusion

We're automating human thinking for the first time in history—a fundamentally different challenge than previous technological revolutions. The path forward requires both individual adaptation (developing uniquely human skills that complement AI) and collective action (new social contracts, possibly including Universal Basic Income as an economic necessity rather than a purely progressive policy).

The greatest risk isn't AI itself, but allowing its benefits to concentrate among a small elite while displacing millions. The choices we make in the next few years about development, regulation, and wealth distribution will determine whether this transformation creates widespread prosperity or devastating inequality.

The future isn't predetermined. This is a human creation we can still influence. The question isn't whether AI will change everything—it's whether we'll guide that change to benefit everyone, not just those who own the machines.
