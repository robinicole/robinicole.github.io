---
showDate: true
summary: "My take on where AI is taking us"
title: "AI and our future"
date: 2025-07-23
draft: false
comments: true
---
# Article summary as a graph
{{< mermaid >}}
graph TD
    A[AI Expansion] --> B[Industrial Revolution]
    B --> C[New Jobs Emerged]
    
    A --> D[AI Revolution]
    C --> D
    
    D --> E[Job Displacement]
    D --> F[Automating Thinking]
    
    E --> G[Fewer Jobs?]
    F --> G
    
    %% Styling to create visual narrative arc
    classDef present fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    classDef past fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef future fill:#ffebee,stroke:#d32f2f,stroke-width:3px
    classDef critical fill:#ffcdd2,stroke:#d32f2f,stroke-width:4px
    
    class A present
    class B,C past
    class D,E future
    class F,G critical
{{< /mermaid >}}

# Introduction
We're living through a technological shift that feels both familiar and unprecedented. While every generation believes it's witnessing history's most important transformation, the AI revolution genuinely appears different—not just in scope, but in what it targets. For the first time, we're automating human thinking itself, not just human labor. This article examines where we are in this transformation, what history teaches us about technological disruption, and what might come next as we navigate uncharted territory.

# Where we are at now ? 
In the last few years the "grand public" has witnessed a rapid expansion of AI. I think there are two reasons for that: we are building on top of solid foundations, and second, AI development feeds itself.

First, even though AI got the headlines with ChatGPT recently, it relies on several other successful research projects. For example, the internet has made it possible to access and process knowledge at a scale never imagined before, computer hardware gave rise to highly efficient GPUs which are the core of neural networks such as ChatGPT, and the improvement of Python - an easy-to-use language which makes it possible for novice developers to experiment with LLMs.

Secondly, progress in research (and in the case that interests us, ML research on LLMs) is a self-reinforcing process. The reason for that is one of the often misunderstood properties of research: 90% of it will be a dead end, but the 10% remaining will have a huge impact. A good LLM can act as a powerful research assistant that will help in the process of identifying those 10%, which should increase the quantity and quality of good research output. And this is the start of a self-reinforcing process where you create better LLMs that help you do better research that helps you do better LLMs that help you do better research... This results in rapid improvements of AI capabilities which seem to have a much harder time plateauing than other research fields.

In this rapid advancement, us as mere humans are seeing our way of working changed significantly as we get to outsource most of our jobs to those chatbots and start to witness an internet where a lot of the content is auto-generated.

# What happened before ? 
To think about the future, I always find it useful to reflect on the past. More specifically, I want to think about the rise of manual labor automation and compare it to the intellectual labor automation that we witness now.

The industrial revolution gives us a blueprint for what might happen. When machines started replacing human muscle power, there was initially a lot of fear and resistance. People were worried about losing their livelihoods, and rightfully so - many traditional crafts and manual jobs simply disappeared.

What we saw was that human-generated things became premium products. Think about handmade furniture versus mass-produced IKEA stuff, or artisanal bread versus factory-made loaves. People started paying more for the "human touch" once machines could do the basic work cheaply and efficiently. There's something about knowing a human crafted something with their hands that adds value.

Only the strongest survived in each industry. The blacksmiths who adapted became specialized metalworkers, the weavers who survived became designers, and new jobs emerged that nobody could have predicted - like machine operators, engineers, and eventually software developers. The key was adaptation and finding where human skills were still irreplaceable.

What's fascinating is how closely this mirrors the industrial revolution pattern. Just as steam engines and machinery amplified human muscle power beyond what anyone thought possible, AI is now amplifying human cognitive power in the same way. The steam engine didn't just replace a few workers - it fundamentally changed what it meant to do physical work. Similarly, AI isn't just replacing a few thinkers - it's changing what it means to do intellectual work. We're seeing the same cycle: initial fear, massive disruption, then adaptation to a new equilibrium where humans and machines work together in ways we couldn't have imagined before. 

# How do we go from there ? 

In the short term, we're about to see the same demand and supply imbalance that hit manual laborers during the industrial revolution, except this time it's coming for white-collar jobs. The supply of code, legal documents, financial analysis, and accounting work is about to explode while demand stays roughly the same. Software engineers, accountants, and lawyers - the knowledge workers who thought they were safe - are going to face the same brutal economics that factory workers faced 150 years ago.

But here's where it gets really ugly from an inequality perspective: we're already seeing a massive bifurcation in who benefits from this transition. AI researchers are getting paid tens of millions of dollars because they're the ones creating the tools, while everyone else is about to see their skills commoditized. It's like being the guy who invented the steam engine versus being the guy whose job got replaced by the steam engine. The gap between the "AI elite" and everyone else is going to become astronomical.

Meanwhile, human-generated content is rapidly becoming the premium option while AI-generated content becomes the IKEA of the information world - cheap, functional, but lacking that special something. You can already see this happening: people are starting to specifically seek out "human-written" articles or "human-coded" software, and they're willing to pay more for it. But just like with handmade furniture, the market for premium human work will be much smaller than the mass market that AI will dominate.

Looking further ahead, the historical parallel gets really interesting - and potentially depressing. During the industrial revolution, when manual jobs disappeared, they were largely replaced by more knowledge-intensive jobs. Factory workers became engineers, farmers became office workers, and so on. But now we're automating the knowledge work itself. So what comes next?

We'll definitely see new jobs emerge around AI - prompt engineers, AI trainers, AI auditors, and roles we can't even imagine yet. But here's the key question: will these new jobs be as numerous as the ones being displaced? History suggests they might not be. When you can replace ten accountants with one AI system that needs only occasional human oversight, the math doesn't work out in favor of employment.

This brings us to an uncomfortable possibility that we've never faced before: we might actually be heading toward a world with fundamentally fewer jobs. During every previous technological revolution, new types of work emerged to absorb displaced workers. But when you're automating thinking itself - the thing that created all those previous "new" jobs - where do you go from there?

This might be when universal basic income stops being a progressive policy idea and becomes an economic necessity. Not because politicians want to be nice, but because the alternative is mass unemployment and social collapse. The challenge will be figuring out how to fund it when most of the value creation is happening through AI systems rather than human labor.

# Conclusion
We're automating human thinking for the first time in history—a fundamentally different challenge than previous technological revolutions. The path forward requires both individual adaptation (developing uniquely human skills that complement AI) and collective action (new social contracts, possibly including Universal Basic Income as economic necessity rather than progressive policy).

The greatest risk isn't AI itself, but allowing its benefits to concentrate among a small elite while displacing millions. The choices we make in the next few years about development, regulation, and wealth distribution will determine whether this transformation creates widespread prosperity or devastating inequality.

The future isn't predetermined. This is a human creation we can still influence. The question isn't whether AI will change everything—it's whether we'll guide that change to benefit everyone, not just those who own the machines.